{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_corrupt_images(folder_path):\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                img.verify()\n",
    "            except Exception as e:\n",
    "                print(f\"Removing corrupt image: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "\n",
    "\n",
    "remove_corrupt_images('C:/DoctorP_dataset_split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31158 images belonging to 31 classes.\n",
      "Found 6682 images belonging to 31 classes.\n",
      "Found 6696 images belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = 'C:/DoctorP_dataset_split'\n",
    "train_path = os.path.join(base_dir, 'train')\n",
    "val_path = os.path.join(base_dir, 'val')\n",
    "test_path = os.path.join(base_dir, 'test')\n",
    "\n",
    "\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_path, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
    "val_gen = val_datagen.flow_from_directory(val_path, target_size=image_size, batch_size=batch_size, class_mode='categorical')\n",
    "test_gen = val_datagen.flow_from_directory(test_path, target_size=image_size, batch_size=batch_size, class_mode='categorical', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31)                3999      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,425,951\n",
      "Trainable params: 167,967\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  \n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(train_gen.num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442badd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "974/974 [==============================] - 840s 848ms/step - loss: 0.5762 - accuracy: 0.8268 - val_loss: 0.3582 - val_accuracy: 0.8830\n",
      "Epoch 2/15\n",
      "974/974 [==============================] - 612s 628ms/step - loss: 0.2876 - accuracy: 0.9036 - val_loss: 0.3140 - val_accuracy: 0.8957\n",
      "Epoch 3/15\n",
      "974/974 [==============================] - 628s 645ms/step - loss: 0.2170 - accuracy: 0.9273 - val_loss: 0.2589 - val_accuracy: 0.9145\n",
      "Epoch 4/15\n",
      "974/974 [==============================] - 695s 713ms/step - loss: 0.1646 - accuracy: 0.9420 - val_loss: 0.2609 - val_accuracy: 0.9175\n",
      "Epoch 5/15\n",
      "974/974 [==============================] - 629s 646ms/step - loss: 0.1425 - accuracy: 0.9490 - val_loss: 0.2509 - val_accuracy: 0.9202\n",
      "Epoch 6/15\n",
      "974/974 [==============================] - 622s 639ms/step - loss: 0.1156 - accuracy: 0.9586 - val_loss: 0.3010 - val_accuracy: 0.9135\n",
      "Epoch 7/15\n",
      "974/974 [==============================] - 560s 575ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.2634 - val_accuracy: 0.9231\n",
      "Epoch 8/15\n",
      "974/974 [==============================] - 510s 524ms/step - loss: 0.0812 - accuracy: 0.9703 - val_loss: 0.3022 - val_accuracy: 0.9135\n",
      "Epoch 9/15\n",
      "974/974 [==============================] - 499s 512ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 0.3177 - val_accuracy: 0.9168\n",
      "Epoch 10/15\n",
      "974/974 [==============================] - 536s 551ms/step - loss: 0.0582 - accuracy: 0.9788 - val_loss: 0.2960 - val_accuracy: 0.9256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('plant_disease_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 100s 477ms/step - loss: 0.2887 - accuracy: 0.9132\n",
      "Test Accuracy: 91.32%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b602b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: plant_disease_model_saved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: plant_disease_model_saved\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"plant_disease_model.h5\")\n",
    "\n",
    "model.save(\"plant_disease_model_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742afc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in these formats: plant_disease_model.h5، plant_disease_model_saved،plant_disease_model.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"plant_disease_model_saved\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "with open(\"plant_disease_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model saved in these formats: plant_disease_model.h5، plant_disease_model_saved،plant_disease_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf45803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TRAIN_PATH=\"C:/DoctorP_dataset_split/train\"\n",
    "class_names = sorted(os.listdir(TRAIN_PATH))\n",
    "\n",
    "with open(\"DISEASES label.txt\", \"w\") as f:\n",
    "    for class_name in class_names:\n",
    "        f.write(class_name + \"\\n\")\n",
    "\n",
    "print(\"SAVED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
